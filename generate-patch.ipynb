{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0443be-2472-467c-b26e-631d55b5be23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda create -n crewai python=3.11\n",
    "# !conda activate crewai -\n",
    "!pip install -q --upgrade google-cloud-aiplatform\n",
    "!pip install -q -U 'crewai[tools]' mdpdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c2495d9e-a3df-49f0-811d-aaef356b2392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "patch-demo-data-folder folder already exists. Contents:\n",
      "\n",
      "cve list: {'CVE-2017-16994'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vertexai\n",
    "import socket\n",
    "import re\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from google.cloud import storage\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "GCS_BUCKET_LOCATION = \"us-east1\"\n",
    "GCS_BUCKET_NAME = \"patch-demo-data-folder\"\n",
    "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n",
    "\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = storage.Bucket(client, GCS_BUCKET_NAME)\n",
    "\n",
    "if bucket.exists()==False:\n",
    "    # Create a Cloud Storage Bucket\n",
    "    print(f\"\\n{GCS_BUCKET_NAME} not exists. \\n\")\n",
    "else:    \n",
    "    print(f\"\\n{GCS_BUCKET_NAME} folder already exists. Contents:\\n\")\n",
    "    \n",
    "def list_all_cves():\n",
    "    bucket = client.bucket(GCS_BUCKET_NAME)    \n",
    "    blobs = bucket.list_blobs()    \n",
    "    cve_list = set();\n",
    "    for blob in blobs:        \n",
    "        parts = blob.name.split('/')\n",
    "        cve_list.add(parts[0])\n",
    "    return cve_list\n",
    "    \n",
    "    \n",
    "cve_list = list_all_cves()\n",
    "print(f'cve list: {cve_list}')\n",
    "# list_folders(GCS_BUCKET_NAME)\n",
    "\n",
    "def extract_patch_content(patch_files):\n",
    "    content = ''\n",
    "    for file in patch_files:\n",
    "        content = content + file.download_as_text()\n",
    "    return content\n",
    "\n",
    "def upload_patch_content(cve, version, file_name, file_content):\n",
    "    '''\n",
    "    upload the patched content to the modified/ folder under the same version\n",
    "    '''\n",
    "    folder_name = f'{cve}/{version}/modified/{file_name}'\n",
    "    print(f'folder name {folder_name}')\n",
    "    folder_blob = bucket.blob(folder_name)\n",
    "    if not folder_blob.exists():\n",
    "        folder_blob.upload_from_string(file_content)\n",
    "        print(f\"Folder {folder_name} created in bucket {GCS_BUCKET_NAME}.\")\n",
    "    else:\n",
    "        folder_blob.upload_from_string(file_content)\n",
    "        # print(f\"Folder {folder_name} already exists in bucket {GCS_BUCKET_NAME}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "884b2b58-ee0d-4e13-ac14-d55dddf22f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVE: CVE-2017-16994\n",
      "what is patch_files, [<Blob: patch-demo-data-folder, CVE-2017-16994/patch-files/373c4557d2aa362702c4c2d41288fb1e54990b7c.patch, 1718350061800224>]\n",
      "4.5.13-rc\n",
      "4.8-rc2\n",
      "  File: CVE-2017-16994/4.8-rc2/pagewalk.c\n",
      "-----summary----\n",
      "[\n",
      "  {\n",
      "    \"old lines\": \"static int walk_hugetlb_range(unsigned long addr, unsigned long end, struct mm_walk *walk)\\n{\\n\\tunsigned long next;\\n\\tpte_t *pte;\\n\\tstruct page *h = walk->hugetlb_entry;\\n\\n\\tif (!h)\\n\\t\\treturn 0;\\n\\n\\tdo {\\n\\t\\tnext = hugetlb_entry_end(h, addr, end);\\n\\t\\tpte = huge_pte_offset(walk->mm, addr & hmask, sz);\\n\\t\\tif (pte && walk->hugetlb_entry)\\n\\t\\t\\terr = walk->hugetlb_entry(pte, hmask, addr, next, walk);\\n\\t} while (addr = next, addr != end);\\n\\n\\treturn err;\\n}\",\n",
      "    \"new lines\": \"static int walk_hugetlb_range(unsigned long addr, unsigned long end, struct mm_walk *walk)\\n{\\n\\tunsigned long next;\\n\\tpte_t *pte;\\n\\tstruct page *h = walk->hugetlb_entry;\\n\\n\\tif (!h)\\n\\t\\treturn 0;\\n\\n\\tdo {\\n\\t\\tnext = hugetlb_entry_end(h, addr, end);\\n\\t\\tpte = huge_pte_offset(walk->mm, addr & hmask, sz);\\n\\t\\tif (pte)\\n\\t\\t\\terr = walk->hugetlb_entry(pte, hmask, addr, next, walk);\\n\\t\\telse if (walk->pte_hole)\\n\\t\\t\\terr = walk->pte_hole(addr, next, walk);\\n\\t} while (addr = next, addr != end);\\n\\n\\treturn err;\\n}\"\n",
      "  }\n",
      "]\n",
      "\n",
      "#include <linux/mm.h>\n",
      "#include <linux/highmem.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/hugetlb.h>\n",
      "\n",
      "static int walk_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,\n",
      "\t\t\t  struct mm_walk *walk)\n",
      "{\n",
      "\tpte_t *pte;\n",
      "\tint err = 0;\n",
      "\n",
      "\tpte = pte_offset_map(pmd, addr);\n",
      "\tfor (;;) {\n",
      "\t\terr = walk->pte_entry(pte, addr, addr + PAGE_SIZE, walk);\n",
      "\t\tif (err)\n",
      "\t\t       break;\n",
      "\t\taddr += PAGE_SIZE;\n",
      "\t\tif (addr == end)\n",
      "\t\t\tbreak;\n",
      "\t\tpte++;\n",
      "\t}\n",
      "\n",
      "\tpte_unmap(pte);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "static int walk_pmd_range(pud_t *pud, unsigned long addr, unsigned long end,\n",
      "\t\t\t  struct mm_walk *walk)\n",
      "{\n",
      "\tpmd_t *pmd;\n",
      "\tunsigned long next;\n",
      "\tint err = 0;\n",
      "\n",
      "\tpmd = pmd_offset(pud, addr);\n",
      "\tdo {\n",
      "again:\n",
      "\t\tnext = pmd_addr_end(addr, end);\n",
      "\t\tif (pmd_none(*pmd) || !walk->vma) {\n",
      "\t\t\tif (walk->pte_hole)\n",
      "\t\t\t\terr = walk->pte_hole(addr, next, walk);\n",
      "\t\t\tif (err)\n",
      "\t\t\t\tbreak;\n",
      "\t\t\tcontinue;\n",
      "\t\t}\n",
      "\t\t/*\n",
      "\t\t * This implies that each ->pmd_entry() handler\n",
      "\t\t * needs to know about pmd_trans_huge() pmds\n",
      "\t\t */\n",
      "\t\tif (walk->pmd_entry)\n",
      "\t\t\terr = walk->pmd_entry(pmd, addr, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\n",
      "\t\t/*\n",
      "\t\t * Check this here so we only break down trans_huge\n",
      "\t\t * pages when we _need_ to\n",
      "\t\t */\n",
      "\t\tif (!walk->pte_entry)\n",
      "\t\t\tcontinue;\n",
      "\n",
      "\t\tsplit_huge_pmd(walk->vma, pmd, addr);\n",
      "\t\tif (pmd_trans_unstable(pmd))\n",
      "\t\t\tgoto again;\n",
      "\t\terr = walk_pte_range(pmd, addr, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\t} while (pmd++, addr = next, addr != end);\n",
      "\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "static int walk_pud_range(pgd_t *pgd, unsigned long addr, unsigned long end,\n",
      "\t\t\t  struct mm_walk *walk)\n",
      "{\n",
      "\tpud_t *pud;\n",
      "\tunsigned long next;\n",
      "\tint err = 0;\n",
      "\n",
      "\tpud = pud_offset(pgd, addr);\n",
      "\tdo {\n",
      "\t\tnext = pud_addr_end(addr, end);\n",
      "\t\tif (pud_none_or_clear_bad(pud)) {\n",
      "\t\t\tif (walk->pte_hole)\n",
      "\t\t\t\terr = walk->pte_hole(addr, next, walk);\n",
      "\t\t\tif (err)\n",
      "\t\t\t\tbreak;\n",
      "\t\t\tcontinue;\n",
      "\t\t}\n",
      "\t\tif (walk->pmd_entry || walk->pte_entry)\n",
      "\t\t\terr = walk_pmd_range(pud, addr, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\t} while (pud++, addr = next, addr != end);\n",
      "\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "static int walk_pgd_range(unsigned long addr, unsigned long end,\n",
      "\t\t\t  struct mm_walk *walk)\n",
      "{\n",
      "\tpgd_t *pgd;\n",
      "\tunsigned long next;\n",
      "\tint err = 0;\n",
      "\n",
      "\tpgd = pgd_offset(walk->mm, addr);\n",
      "\tdo {\n",
      "\t\tnext = pgd_addr_end(addr, end);\n",
      "\t\tif (pgd_none_or_clear_bad(pgd)) {\n",
      "\t\t\tif (walk->pte_hole)\n",
      "\t\t\t\terr = walk->pte_hole(addr, next, walk);\n",
      "\t\t\tif (err)\n",
      "\t\t\t\tbreak;\n",
      "\t\t\tcontinue;\n",
      "\t\t}\n",
      "\t\tif (walk->pmd_entry || walk->pte_entry)\n",
      "\t\t\terr = walk_pud_range(pgd, addr, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\t} while (pgd++, addr = next, addr != end);\n",
      "\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef CONFIG_HUGETLB_PAGE\n",
      "static unsigned long hugetlb_entry_end(struct hstate *h, unsigned long addr,\n",
      "\t\t\t\t       unsigned long end)\n",
      "{\n",
      "\tunsigned long boundary = (addr & huge_page_mask(h)) + huge_page_size(h);\n",
      "\treturn boundary < end ? boundary : end;\n",
      "}\n",
      "\n",
      "static int walk_hugetlb_range(unsigned long addr, unsigned long end,\n",
      "\t\t\t      struct mm_walk *walk)\n",
      "{\n",
      "\tstruct vm_area_struct *vma = walk->vma;\n",
      "\tstruct hstate *h = hstate_vma(vma);\n",
      "\tunsigned long next;\n",
      "\tunsigned long hmask = huge_page_mask(h);\n",
      "\tpte_t *pte;\n",
      "\tint err = 0;\n",
      "\n",
      "\tdo {\n",
      "\t\tnext = hugetlb_entry_end(h, addr, end);\n",
      "\t\tpte = huge_pte_offset(walk->mm, addr & hmask);\n",
      "\t\tif (pte)\n",
      "\t\t\terr = walk->hugetlb_entry(pte, hmask, addr, next, walk);\n",
      "\t\telse if (walk->pte_hole)\n",
      "\t\t\terr = walk->pte_hole(addr, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\t} while (addr = next, addr != end);\n",
      "\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#else /* CONFIG_HUGETLB_PAGE */\n",
      "static int walk_hugetlb_range(unsigned long addr, unsigned long end,\n",
      "\t\t\t      struct mm_walk *walk)\n",
      "{\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "#endif /* CONFIG_HUGETLB_PAGE */\n",
      "\n",
      "/*\n",
      " * Decide whether we really walk over the current vma on [@start, @end)\n",
      " * or skip it via the returned value. Return 0 if we do walk over the\n",
      " * current vma, and return 1 if we skip the vma. Negative values means\n",
      " * error, where we abort the current walk.\n",
      " */\n",
      "static int walk_page_test(unsigned long start, unsigned long end,\n",
      "\t\t\tstruct mm_walk *walk)\n",
      "{\n",
      "\tstruct vm_area_struct *vma = walk->vma;\n",
      "\n",
      "\tif (walk->test_walk)\n",
      "\t\treturn walk->test_walk(start, end, walk);\n",
      "\n",
      "\t/*\n",
      "\t * vma(VM_PFNMAP) doesn't have any valid struct pages behind VM_PFNMAP\n",
      "\t * range, so we don't walk over it as we do for normal vmas. However,\n",
      "\t * Some callers are interested in handling hole range and they don't\n",
      "\t * want to just ignore any single address range. Such users certainly\n",
      "\t * define their ->pte_hole() callbacks, so let's delegate them to handle\n",
      "\t * vma(VM_PFNMAP).\n",
      "\t */\n",
      "\tif (vma->vm_flags & VM_PFNMAP) {\n",
      "\t\tint err = 1;\n",
      "\t\tif (walk->pte_hole)\n",
      "\t\t\terr = walk->pte_hole(start, end, walk);\n",
      "\t\treturn err ? err : 1;\n",
      "\t}\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int __walk_page_range(unsigned long start, unsigned long end,\n",
      "\t\t\tstruct mm_walk *walk)\n",
      "{\n",
      "\tint err = 0;\n",
      "\tstruct vm_area_struct *vma = walk->vma;\n",
      "\n",
      "\tif (vma && is_vm_hugetlb_page(vma)) {\n",
      "\t\tif (walk->hugetlb_entry)\n",
      "\t\t\terr = walk_hugetlb_range(start, end, walk);\n",
      "\t} else\n",
      "\t\terr = walk_pgd_range(start, end, walk);\n",
      "\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "/**\n",
      " * walk_page_range - walk page table with caller specific callbacks\n",
      " *\n",
      " * Recursively walk the page table tree of the process represented by @walk->mm\n",
      " * within the virtual address range [@start, @end). During walking, we can do\n",
      " * some caller-specific works for each entry, by setting up pmd_entry(),\n",
      " * pte_entry(), and/or hugetlb_entry(). If you don't set up for some of these\n",
      " * callbacks, the associated entries/pages are just ignored.\n",
      " * The return values of these callbacks are commonly defined like below:\n",
      " *  - 0  : succeeded to handle the current entry, and if you don't reach the\n",
      " *         end address yet, continue to walk.\n",
      " *  - >0 : succeeded to handle the current entry, and return to the caller\n",
      " *         with caller specific value.\n",
      " *  - <0 : failed to handle the current entry, and return to the caller\n",
      " *         with error code.\n",
      " *\n",
      " * Before starting to walk page table, some callers want to check whether\n",
      " * they really want to walk over the current vma, typically by checking\n",
      " * its vm_flags. walk_page_test() and @walk->test_walk() are used for this\n",
      " * purpose.\n",
      " *\n",
      " * struct mm_walk keeps current values of some common data like vma and pmd,\n",
      " * which are useful for the access from callbacks. If you want to pass some\n",
      " * caller-specific data to callbacks, @walk->private should be helpful.\n",
      " *\n",
      " * Locking:\n",
      " *   Callers of walk_page_range() and walk_page_vma() should hold\n",
      " *   @walk->mm->mmap_sem, because these function traverse vma list and/or\n",
      " *   access to vma's data.\n",
      " */\n",
      "int walk_page_range(unsigned long start, unsigned long end,\n",
      "\t\t    struct mm_walk *walk)\n",
      "{\n",
      "\tint err = 0;\n",
      "\tunsigned long next;\n",
      "\tstruct vm_area_struct *vma;\n",
      "\n",
      "\tif (start >= end)\n",
      "\t\treturn -EINVAL;\n",
      "\n",
      "\tif (!walk->mm)\n",
      "\t\treturn -EINVAL;\n",
      "\n",
      "\tVM_BUG_ON_MM(!rwsem_is_locked(&walk->mm->mmap_sem), walk->mm);\n",
      "\n",
      "\tvma = find_vma(walk->mm, start);\n",
      "\tdo {\n",
      "\t\tif (!vma) { /* after the last vma */\n",
      "\t\t\twalk->vma = NULL;\n",
      "\t\t\tnext = end;\n",
      "\t\t} else if (start < vma->vm_start) { /* outside vma */\n",
      "\t\t\twalk->vma = NULL;\n",
      "\t\t\tnext = min(end, vma->vm_start);\n",
      "\t\t} else { /* inside vma */\n",
      "\t\t\twalk->vma = vma;\n",
      "\t\t\tnext = min(end, vma->vm_end);\n",
      "\t\t\tvma = vma->vm_next;\n",
      "\n",
      "\t\t\terr = walk_page_test(start, next, walk);\n",
      "\t\t\tif (err > 0) {\n",
      "\t\t\t\t/*\n",
      "\t\t\t\t * positive return values are purely for\n",
      "\t\t\t\t * controlling the pagewalk, so should never\n",
      "\t\t\t\t * be passed to the callers.\n",
      "\t\t\t\t */\n",
      "\t\t\t\terr = 0;\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t}\n",
      "\t\t\tif (err < 0)\n",
      "\t\t\t\tbreak;\n",
      "\t\t}\n",
      "\t\tif (walk->vma || walk->pte_hole)\n",
      "\t\t\terr = __walk_page_range(start, next, walk);\n",
      "\t\tif (err)\n",
      "\t\t\tbreak;\n",
      "\t} while (start = next, start < end);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "int walk_page_vma(struct vm_area_struct *vma, struct mm_walk *walk)\n",
      "{\n",
      "\tint err;\n",
      "\n",
      "\tif (!walk->mm)\n",
      "\t\treturn -EINVAL;\n",
      "\n",
      "\tVM_BUG_ON(!rwsem_is_locked(&walk->mm->mmap_sem));\n",
      "\tVM_BUG_ON(!vma);\n",
      "\twalk->vma = vma;\n",
      "\terr = walk_page_test(vma->vm_start, vma->vm_end, walk);\n",
      "\tif (err > 0)\n",
      "\t\treturn 0;\n",
      "\tif (err < 0)\n",
      "\t\treturn err;\n",
      "\treturn __walk_page_range(vma->vm_start, vma->vm_end, walk);\n",
      "}\n",
      "folder name CVE-2017-16994/4.8-rc2/modified/pagewalk.c\n"
     ]
    }
   ],
   "source": [
    "def gemini_pro(full_prompt, responseType):\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    responses = model.generate_content(\n",
    "    full_prompt,\n",
    "    generation_config={\n",
    "        \"candidate_count\": 1,\n",
    "        \"max_output_tokens\": 8190,\n",
    "        \"response_mime_type\": responseType,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 1\n",
    "    },stream=False,)    \n",
    "    return(responses.text)\n",
    "\n",
    "def extract_codesnippets_from_patch(patch_context):\n",
    "    # full_prompt = \"\"\"\\    \n",
    "    # From this file: \n",
    "    # ---file start---\n",
    "    # {patch_context}\n",
    "    # ---file end---\n",
    "    # I want to remove the header and description, only keep the code snippets from diff,\n",
    "    # in the remaining part\n",
    "    # then, I want to identify the old lines and new lines\n",
    "    # should only be one array containing all the modification\n",
    "    # \"\"\"\n",
    "    full_prompt = \"\"\"\\    \n",
    "    From this file: \n",
    "    ---file start---\n",
    "    {patch_context}\n",
    "    ---file end---\n",
    "    I want to remove the header and description, only keep the code snippets from diff,\n",
    "    in the remaining part\n",
    "    then, I want to identify the old lines and new lines for each diff\n",
    "    should only output an array, which containing objects, each object has 2 propertys\n",
    "    \n",
    "    \"old lines\" property, containing old code snippet, \n",
    "    \"new lines\" property, containing new code snippet,\n",
    "    \n",
    "    output the object only\n",
    "    \"\"\"    \n",
    "    formatted_prompt = full_prompt.format(\n",
    "        patch_context=patch_context\n",
    "    )\n",
    "    # return formatted_prompt\n",
    "    return gemini_pro(formatted_prompt, \"application/json\")\n",
    "\n",
    "def extract_function_name(steps):\n",
    "    full_prompt = \"\"\"\\    \n",
    "    From this code snippet: \n",
    "    ---file start---\n",
    "    {steps}\n",
    "    ---file end---\n",
    "    \n",
    "    which function gets modified?\n",
    "    \n",
    "    output the function name\n",
    "    \"\"\"    \n",
    "    formatted_prompt = full_prompt.format(\n",
    "        steps=steps\n",
    "    )\n",
    "    # return formatted_prompt\n",
    "    return gemini_pro(formatted_prompt, \"text/plain\")    \n",
    "    \n",
    "# def trim_content(steps):\n",
    "#     full_prompt = \"\"\"\\    \n",
    "#     From this array: \n",
    "    \n",
    "#     ---array start---\n",
    "#     {steps}\n",
    "#     ---array end---\n",
    "\n",
    "#     remove any + or - or any empty space or any tabs at the start of each content\n",
    "    \n",
    "#     output the array\n",
    "#     \"\"\"\n",
    "#     formatted_prompt = full_prompt.format(\n",
    "#         steps=steps\n",
    "#     )    \n",
    "#     return gemini_pro(formatted_prompt, \"application/json\")\n",
    "\n",
    "def generate_patched_file(target_file, diff, function_name):\n",
    "    full_prompt = \"\"\"\\    \n",
    "    You are an regex agent, you can replace old code with new code.\n",
    "    You only do necessary changes when replace old code with new code.\n",
    "    \n",
    "    Now, I have this diff:\n",
    "    \n",
    "    ---diff start---\n",
    "    {diff}\n",
    "    ---diff end---\n",
    "    \n",
    "    in this target_file\n",
    "    ---target_file start---\n",
    "    {target_file}\n",
    "    ---target_file end---\n",
    "    \n",
    "    modify the target_file according to diff, inside {function_name} replace the old code with new code\n",
    "    add a trailing brief comment wherever you modified\n",
    "    \n",
    "    output the full file in text/plain format\n",
    "    \"\"\"   \n",
    "    formatted_prompt = full_prompt.format(\n",
    "        target_file=target_file,\n",
    "        diff=diff,\n",
    "        function_name=function_name\n",
    "    )   \n",
    "    # full_prompt = f'Use these steps {steps} to modify the file {target_file}, for each line, find the value in the \"old\" property in the file content, and replace with the content in the \"new\" property, output the modified file'\n",
    "    return gemini_pro(formatted_prompt, \"text/plain\")\n",
    "\n",
    "def main():\n",
    "    bucket = client.get_bucket(GCS_BUCKET_NAME)\n",
    "    for cve in sorted(cve_list):\n",
    "        print(f'CVE: {cve}')\n",
    "        \n",
    "        # for test case purpose only\n",
    "        if 'CVE-2017-16994' not in cve:\n",
    "            print(f'Unknown CVEs')\n",
    "            return\n",
    "        \n",
    "        # Step 1: Get the CVE patch files or related patches\n",
    "        all_files_in_patch_files_folder = list(bucket.list_blobs(prefix=f'{cve}/patch-files/'))\n",
    "        patch_files = [blob for blob in all_files_in_patch_files_folder if blob.name.endswith('.patch')]\n",
    "        print(f'what is patch_files, {patch_files}')\n",
    "        if len(patch_files) > 1:\n",
    "            print(f'{cve} has more than 1 patch')\n",
    "        patch_content = extract_patch_content(patch_files)        \n",
    "        \n",
    "        # Step 2: Get the target vulnerable files\n",
    "        all_version_files = list(bucket.list_blobs(prefix=f'{cve}/'))\n",
    "        for blob in all_version_files:            \n",
    "            parts = blob.name.split('/')\n",
    "            if len(parts) > 2 and parts[1] != 'patch-files':\n",
    "                version_number = parts[1]\n",
    "                print(version_number)\n",
    "                # Optionally, list files under each first-level version_number folder\n",
    "                folder_prefix = f'{cve}/{version_number}/'\n",
    "                for blob in bucket.list_blobs(prefix=folder_prefix, delimiter='/'):\n",
    "                    if blob.name != folder_prefix:  # To avoid printing the folder itself\n",
    "                        print(f\"  File: {blob.name}\")\n",
    "                        target_file = blob.download_as_text()\n",
    "                        \n",
    "                        #Step 3: generate patch file for each version\n",
    "                        \n",
    "                        steps = extract_codesnippets_from_patch(patch_content)\n",
    "                        print('-----summary----')\n",
    "                        print(steps)\n",
    "                        # steps = trim_content(diff_summary)\n",
    "                        # print('-----steps----')\n",
    "                        function_name = extract_function_name(steps)\n",
    "                        # print(diff_summary)\n",
    "                        # instructions = convert_steps_to_instruction(steps)\n",
    "                        # print('-----instructions----')\n",
    "                        # print(instructions)\n",
    "                        new_content = generate_patched_file(target_file, steps, function_name)\n",
    "                        # print('-----result----')\n",
    "                        print(new_content)\n",
    "                        file_name = blob.name.split('/')[2] # CVE/version/file_name\n",
    "                        upload_patch_content(cve, version_number, file_name, new_content)\n",
    "                        return\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "        \n",
    "#         # Create tasks for the agents\n",
    "#         backporting_patch_task = Task(\n",
    "#             description=f'Given the CVE id: {cve}, with description: {description}, and I have this patch file: {patch_content}, can you fix the target vulnerable file of this repo with an older version: {file_content}',\n",
    "#             agent=cve_expert,\n",
    "#             expected_output='A new file with minimum code change from the target vulnerable file, output in original target file format'\n",
    "#         )\n",
    "\n",
    "#         crew = Crew(\n",
    "#           agents=[senior_security_developer],\n",
    "#           tasks=[backporting_patch_task],\n",
    "#           verbose=True,\n",
    "#           process=Process.sequential\n",
    "#         )\n",
    "\n",
    "#         result = crew.kickoff()\n",
    "        # print(result)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e041e-8a59-4970-babe-6767f493d7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
